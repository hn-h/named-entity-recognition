{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNFbX1QgeCc0WbcXNFnF19o"
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1IIXIrnpUTL"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7V_p-xQqp30"
      },
      "source": [
        "#lets import our data\n",
        "data = pd.read_csv(\"/content/ner_dataset.csv\", encoding=\"latin1\")\n",
        "data = data.fillna(method=\"ffill\")\n",
        "\n",
        "words = list(set(data[\"Word\"].values))\n",
        "tags  = list(set(data[\"Tag\"].values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TNAlbkOqwSq"
      },
      "source": [
        "#convert the data to lists of tuples\n",
        "to_list_words = lambda sentence: sentence[\"Word\"].values.tolist()\n",
        "to_list_tags = lambda sentence: sentence[\"Tag\"].values.tolist()\n",
        "words_list = data.groupby(\"Sentence #\").apply(to_list_words).to_list()\n",
        "tags_list = data.groupby(\"Sentence #\").apply(to_list_tags).to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B_lJYP0Gwsu"
      },
      "source": [
        "t = Tokenizer(filters='', lower=False, oov_token=1)\n",
        "t.fit_on_texts(words)\n",
        "encoded_words = t.texts_to_sequences(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cFteOMjpKMT"
      },
      "source": [
        "t_tags=Tokenizer(filters='', lower=False)\n",
        "t_tags.fit_on_texts(tags)\n",
        "encoded_tags=t_tags.texts_to_sequences(tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8Z906rVPPGy"
      },
      "source": [
        "X = t.texts_to_sequences(words_list)\n",
        "X = pad_sequences(sequences=X, maxlen=81, padding='post')\n",
        "\n",
        "Y = t_tags.texts_to_sequences(tags_list)\n",
        "Y = pad_sequences(sequences=Y, maxlen=81, padding='post')\n",
        "Y = [to_categorical(s , num_classes=len(tags)+1) for s in Y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhTgXyc9sI-0"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6iVOPAQRLtY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "23efdbd4-d6be-4e19-ac8d-391db0211a4d"
      },
      "source": [
        "!pip -q install git+https://www.github.com/keras-team/keras-contrib.git sklearn_crfsuite\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Dense, Bidirectional, TimeDistributed, Dropout\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_accuracy\n",
        "\n",
        "\n",
        "input_sequence = Input(shape = (81,))\n",
        "model = Embedding(input_dim = len(words)+1, output_dim = 48, input_length=81, mask_zero=True)(input_sequence)\n",
        "model = Bidirectional(LSTM(units=64, return_sequences=True, recurrent_dropout=0.1)) (model)\n",
        "model = TimeDistributed(Dense(48, activation=\"relu\"))(model)\n",
        "crf = CRF(units = len(tags) + 1)\n",
        "output_sequence = crf(model)\n",
        "model = Model(input_sequence,output_sequence)\n",
        "model.compile(optimizer=\"rmsprop\", loss=crf_loss, metrics=[crf_accuracy])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 81)                0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 81, 48)            1688592   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 81, 128)           57856     \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 81, 48)            6192      \n",
            "_________________________________________________________________\n",
            "crf_3 (CRF)                  (None, 81, 18)            1242      \n",
            "=================================================================\n",
            "Total params: 1,753,882\n",
            "Trainable params: 1,753,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD6q7u-auTKs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "7072ef8a-4f1e-4e6f-b972-2ae19763b82f"
      },
      "source": [
        "history = model.fit(X_train, np.array(Y_train), batch_size=256, epochs=8, validation_split=0.1)\n",
        "prediction = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 38846 samples, validate on 4317 samples\n",
            "Epoch 1/8\n",
            "38846/38846 [==============================] - 84s 2ms/step - loss: 10.4015 - crf_accuracy: 0.8374 - val_loss: 10.0536 - val_crf_accuracy: 0.8859\n",
            "Epoch 2/8\n",
            "38846/38846 [==============================] - 79s 2ms/step - loss: 9.9750 - crf_accuracy: 0.9177 - val_loss: 9.9041 - val_crf_accuracy: 0.9400\n",
            "Epoch 3/8\n",
            "38846/38846 [==============================] - 78s 2ms/step - loss: 9.8604 - crf_accuracy: 0.9522 - val_loss: 9.8351 - val_crf_accuracy: 0.9561\n",
            "Epoch 4/8\n",
            "38846/38846 [==============================] - 78s 2ms/step - loss: 9.8106 - crf_accuracy: 0.9645 - val_loss: 9.8114 - val_crf_accuracy: 0.9617\n",
            "Epoch 5/8\n",
            "38846/38846 [==============================] - 77s 2ms/step - loss: 9.7893 - crf_accuracy: 0.9699 - val_loss: 9.7960 - val_crf_accuracy: 0.9660\n",
            "Epoch 6/8\n",
            "38846/38846 [==============================] - 78s 2ms/step - loss: 9.7771 - crf_accuracy: 0.9729 - val_loss: 9.7871 - val_crf_accuracy: 0.9678\n",
            "Epoch 7/8\n",
            "38846/38846 [==============================] - 77s 2ms/step - loss: 9.7692 - crf_accuracy: 0.9750 - val_loss: 9.7834 - val_crf_accuracy: 0.9676\n",
            "Epoch 8/8\n",
            "38846/38846 [==============================] - 78s 2ms/step - loss: 9.7631 - crf_accuracy: 0.9764 - val_loss: 9.7795 - val_crf_accuracy: 0.9690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rsbow_ov9US",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "3e084285-aea7-42ae-8806-89dafae9974a"
      },
      "source": [
        "# !pip -q install sklearn_crfsuite\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "Y_test_ = np.argmax(Y_test,-1)\n",
        "prediction_=np.argmax(prediction,-1)\n",
        "Y_test_taged = t_tags.sequences_to_texts(Y_test_)\n",
        "prediction_taged = t_tags.sequences_to_texts(prediction_)\n",
        "Y_test_taged = [s.split() for s in Y_test_taged]\n",
        "prediction_taged = [s.split() for s in prediction_taged]\n",
        "metrics = flat_classification_report(Y_test_taged,prediction_taged)\n",
        "print(metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.00      0.00      0.00        36\n",
            "       B-eve       0.67      0.13      0.22        31\n",
            "       B-geo       0.85      0.90      0.87      3754\n",
            "       B-gpe       0.97      0.93      0.95      1558\n",
            "       B-nat       0.00      0.00      0.00        22\n",
            "       B-org       0.81      0.70      0.75      2057\n",
            "       B-per       0.82      0.84      0.83      1630\n",
            "       B-tim       0.94      0.84      0.89      2024\n",
            "       I-art       0.00      0.00      0.00        23\n",
            "       I-eve       0.00      0.00      0.00        23\n",
            "       I-geo       0.77      0.81      0.79       710\n",
            "       I-gpe       0.79      0.55      0.65        20\n",
            "       I-nat       0.00      0.00      0.00         4\n",
            "       I-org       0.80      0.78      0.79      1758\n",
            "       I-per       0.85      0.88      0.87      1682\n",
            "       I-tim       0.90      0.70      0.79       642\n",
            "           O       0.99      0.99      0.99     88745\n",
            "\n",
            "   micro avg       0.97      0.97      0.97    104719\n",
            "   macro avg       0.60      0.53      0.55    104719\n",
            "weighted avg       0.97      0.97      0.97    104719\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNNquhiIDtUV"
      },
      "source": [
        "quote = 'The 1906 San Francisco earthquake was the biggest earthquake lol lol that has ever hit San Francisco on April 18, 1906'\n",
        "quote = quote.split(' ')\n",
        "quote_input=[]\n",
        "UNK_words=[]\n",
        "for i in range(len(quote)):\n",
        "  quote[i]=quote[i].strip(',!.?:')\n",
        "  s_tag = t.texts_to_sequences([quote[i]])\n",
        "  if s_tag == [[1]]:\n",
        "    UNK_words.append(quote[i])\n",
        "  else:\n",
        "    quote_input.append(quote[i])\n",
        "\n",
        "quote_input=t.texts_to_sequences([quote_input])\n",
        "\n",
        "quote_input=pad_sequences(sequences=quote_input, maxlen=81, padding='post')\n",
        "pred=model.predict(quote_input)\n",
        "pred=np.argmax(pred,-1)\n",
        "pred_taged = t_tags.sequences_to_texts(pred)[0].split()\n",
        "\n",
        "for i in quote:\n",
        "  if i in UNK_words:\n",
        "    print('{:20}=====>         UNK'.format(i))\n",
        "  else:\n",
        "    print('{:20}=====>         {:7}'.format(i,pred_taged.pop(0)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}